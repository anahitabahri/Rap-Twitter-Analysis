library(rsconnect)
rsconnect::setAccountInfo(name='anahita', token='752627A4D84EF0F66F6372ABA42DD603', secret='LKbncyzrBziyC78eJUgfWc3JV/7f2hznisNNx9O5')
library(rsconnect)
rsconnect::deployApp('path/to/your/app')
knitr::opts_chunk$set(echo = TRUE,out.width="0.9\\linewidth")
library(ggplot2)
library(knitr)
library(arm)
library(data.table)
library(foreign)
library(car)
risky_behaviors<-read.dta("http://www.stat.columbia.edu/~gelman/arm/examples/risky.behavior/risky_behaviors.dta")
head(risky_behaviors)
poisson1 <- glm(round(fupacts) ~ women_alone + couples, data = risky_behaviors, family = poisson)
display(poisson1)
plot(fitted(poisson1),rstandard(poisson1))
n <- nrow(risky_behaviors) # 434 data points (rows)
n
k <- length(poisson1$coef) # 3 linear predictors
k
yhat <- predict(poisson1, type="response")
z <- (risky_behaviors$fupacts-yhat)/sqrt(yhat)
cat ("sum of squared standardized residuals is ", sum(z^2), "\n")
cat ("overdispersion ratio is ", sum(z^2)/(n-k), "\n")
n-k
cat ("p-value of overdispersion test is ", pchisq (sum(z^2), n-k), "\n")
summary(poisson1) # dispersion paramter for poisson family taken to be 1
poisson2 <- glm(round(fupacts) ~ women_alone + couples + bs_hiv + sex, data = risky_behaviors, family = poisson)
display(poisson2)
poisson3 <- glm(round(fupacts) ~ women_alone + couples + bs_hiv + sex, data = risky_behaviors, family = poisson, offset = log(bupacts+1))
display(poisson3)
poisson4 <- glm(round(fupacts) ~ women_alone + couples + bs_hiv + sex + bupacts, data = risky_behaviors, family = poisson)
display(poisson4)
poisson4 <- glm(round(fupacts) ~ women_alone + couples + bs_hiv + sex + round(bupacts), data = risky_behaviors, family = poisson)
display(poisson4)
plot(x=log(risky_behaviors$bupacts+1), y=log(risky_behaviors$fupacts+1))
n <- nrow(risky_behaviors) # 434 data points (rows)
n
k <- length(poisson4$coef) # 5 linear predictors
k
yhat <- predict(poisson4, type="response")
z <- (risky_behaviors$fupacts-yhat)/sqrt(yhat)
cat ("sum of squared standardized residuals is ", sum(z^2), "\n")
cat ("overdispersion ratio is ", sum(z^2)/(n-k), "\n")
cat ("p-value of overdispersion test is ", pchisq (sum(z^2), n-k), "\n")
n-k
poisson5 <- glm(round(fupacts) ~ women_alone + couples + bs_hiv + sex + round(bupacts), data = risky_behaviors, family = quasipoisson)
display(poisson5)
View(risky_behaviors)
nes5200<-read.dta("http://www.stat.columbia.edu/~gelman/arm/examples/nes/nes5200_processed_voters_realideo.dta")
saveRDS(nes5200,"nes5200.rds")
nes5200<-readRDS("nes5200.rds")
nes5200_dt <- data.table(nes5200)
yr <- 2000
nes5200_dt_s<-nes5200_dt[ year==yr,]
nes5200_dt_s$income <- droplevels(nes5200_dt_s$income)
nes5200_dt_s$partyid7 <- droplevels(nes5200_dt_s$partyid7)
polr1 <- polr(partyid7 ~ ideo + race + gender + age, Hess=TRUE, data=nes5200_dt_s)
summary(polr1)
polr2 <- polr(partyid7 ~ ideo + race + gender + age + educ1 + income + religion, Hess=TRUE, data=nes5200_dt_s)
summary(polr2)
kable(summary(polr1))
vglm1 <- vglm(partyid7 ~ ideo + race + gender, data = nes5200_dt_s, family = multinomial)
library(VGAM)
vglm1 <- vglm(partyid7 ~ ideo + race + gender, data = nes5200_dt_s, family = multinomial)
predict(vglm1,newdata=data.frame(ideo=factor(c("1. liberal" ,"3. moderate ('middle of the road')" )),race=factor(c("1. white","1. white")),gender=factor(c("1. male","1. male"))))
polr3 <- polr(partyid7 ~ real_ideo + female , data=nes5200_dt_s)
fitted(polr3,newdata=data.frame(real_ideo=c(1,3),ideo=factor(c("1. liberal" ,"3. moderate ('middle of the road')" )),race=factor(c("1. white","1. white")),female=c(1,1),gender=factor(c("1. male","1. male"))))
plot(fitted(polr3,newdata=data.frame(real_ideo=c(1,3),ideo=factor(c("1. liberal" ,"3. moderate ('middle of the road')" )),race=factor(c("1. white","1. white")),female=c(1,1),gender=factor(c("1. male","1. male")))))
fitted(polr3,newdata=data.frame(real_ideo=c(1,3),ideo=factor(c("1. liberal" ,"3. moderate ('middle of the road')" )),race=factor(c("1. white","1. white")),female=c(1,1),gender=factor(c("1. male","1. male"))))
display(polr3)
summary(vglm1)
summary(polr3)
confint(vglm1)
multi.log <- polr(partyid3 ~ ideo + race + age_10, Hess=TRUE, data=nes5200_dt_s)
summary(multi.log)
confint(multi.log)
confint(multi.log)
confint(polr3)
confint(vlgm1)
confint(vglm1)
confint(polr1)
confint(polr3)
summary(polr3)
summary(vglm1)
binnedplot(predict(vglm1), resid(vglm1))
binnedplot(fitted(vglm1), resid(vglm1))
plot(fitted(vglm1))
head(fitted(vglm1))
infludenza<-data.frame( treatment = c("placebo",  "placebo",  "placebo",  "vaccine" , "vaccine" , "vaccine" )  ,
response   = c("small", "moderate", "large" ,  "small" ,"moderate","large" ),
frequency = c( 25,8,5,6,18,11 ))
infludenza
chisq.test(infludenza)
pearson.resid<-resid(infludenza,type="pearson") std.resid<-rstandard(infludenza,type="pearson") sum(pearson.resid^2) # pearson chi-square statistics
infludenza
infludenza2 <- spread(infludenza, response, frequency)
library(tidyr)
infludenza2 <- spread(infludenza, response, frequency)
infludenza2
chisq.test(infludenza2)
chisq.test(infludenza2)
infludenza2.is.data.frame()
chisq.test(infludenza2)
fisher.test(infludenza2)
chisq.test(table(infludenza2))
Desc(infludenza2)
install.packages('desc')
library(desc)
Desc(infludenza2)
plot(infludenza2)
infludenza2.is.table()
is.table(infludenza2)
is.data.frame(infludenza2)
infludenza2 <- as.table(infludenza2)
is.table(infludenza)
is.data.frame(infludenza)
infludenza2
lapply(infludenza2[, c("treatment", "large", "moderate","small")], table)
ftable(xtabs(~ treatment + large + moderate + small, data = infludenza2))
infludenza2
is.table(infludenza2)
ftable(infludenza2)
library(gmodels)
CrossTable(infludenza2,prop.t=FALSE,prop.r=FALSE,prop.c=FALSE)
infludenza2
TreatmentSize <- margin.table(infludenza2, c(1, 2))
knitr::opts_chunk$set(echo = TRUE,out.width="0.9\\linewidth",dev="png",fig.align  = 'center')
library(ggplot2)
library(knitr)
library(arm)
library(data.table)
library(foreign)
library(car)
library(stringr)
library(rstan)
library(zoo)
# Read in the data from an excel-format ".csv" file
hiv.data.raw <- fread ("http://www.stat.columbia.edu/~gelman/arm/examples/cd4/allvar.csv")
invisible(hiv.data.raw[,ok := !is.na(CD4PCT) ])
hiv.data<-hiv.data.raw[ok==TRUE]
invisible(hiv.data[,y :=sqrt (CD4PCT)])
# kid's age (yrs) at the beginning of the study
invisible(hiv.data[,age.baseline := baseage ]  )
# kids age (yrs) at the time of measurement
invisible(hiv.data[,age.measurement := visage ] )
invisible(hiv.data[,time := visage - baseage ] )
setnames(hiv.data,"treatmnt","treatment")
knitr::opts_chunk$set(echo = TRUE,out.width="0.9\\linewidth",dev="png",fig.align  = 'center')
library(ggplot2)
library(knitr)
library(arm)
library(data.table)
library(foreign)
library(car)
library(stringr)
library(rstan)
library(zoo)
# Read in the data from an excel-format ".csv" file
hiv.data.raw <- fread ("http://www.stat.columbia.edu/~gelman/arm/examples/cd4/allvar.csv")
invisible(hiv.data.raw[,ok := !is.na(CD4PCT) ])
hiv.data<-hiv.data.raw[ok==TRUE]
invisible(hiv.data[,y :=sqrt (CD4PCT)])
# kid's age (yrs) at the beginning of the study
invisible(hiv.data[,age.baseline := baseage ]  )
# kids age (yrs) at the time of measurement
invisible(hiv.data[,age.measurement := visage ] )
invisible(hiv.data[,time := visage - baseage ] )
setnames(hiv.data,"treatmnt","treatment")
head(hiv.data)
model <- lmer(y ~ time + (1|newpid),data=hiv.data)
model1 <- lmer(y ~ time + treatment + age.baseline + (1|newpid),data=hiv.data)
length((subset$`COB SAM Full Address`)) # lots of full addresses. 11,672
library(RPostgreSQL)
host <- "analyticsga-east2.c20gkj5cvu3l.us-east-1.rds.amazonaws.com"
port <- "5432"
username <- "analytics_student"
password <- "analyticsga"
## Use the name of the specific database you will access
dbname <- "iowa_liquor_sales_database"
## Specify the PostreSQL driver
drv <- dbDriver("PostgreSQL")
## Now establish the connection
con <- dbConnect(drv, user = username, password = password,
dbname = dbname, port = port, host = host)
tail(r3) # lots of NAs. Let's remove those. First let's create a df with case_cost
case_cost <- dbGetQuery(con, statement = paste("SELECT cast(case_cost AS NUMERIC)
FROM products"))
class(products$case_cost) # numeric!
library(dplyr)
case_cost <- case_cost %>% filter(case_cost!='NA') %>% arrange(case_cost)
hist(case_cost$case_cost) # doesn't look good . . . let's manipulate this using ggplot2
# before that, let's look at summary stats
min(case_cost$case_cost) # 0, as expected. should we even have these 0s? well, since there aren't many, we can keep them.
max(case_cost$case_cost) # 7049.7
mean(case_cost$case_cost) # 111.4349
median(case_cost$case_cost) # 83
library(ggplot2)
# create a ggplot object
case_cost_gp <- ggplot(case_cost)
tail(case_cost$case_cost) # let's have 3000 as limit. we don't need last 3 for now.
case_cost_gp + aes(x=case_cost)+
geom_histogram() +
ggtitle("Histogram of Case Cost") +
labs(x="Case Cost",y="Frequency")
# doesn't really tell a good story. let's zoom into 0 - 1000 area
case_cost_gp + aes(x=case_cost)+
geom_histogram() +
ggtitle("Histogram of Case Cost") +
labs(x="Case Cost",y="Frequency") +
scale_x_continuous(limits = c(0,1000))
# let's go down even more. perhaps to 300
case_cost_gp + aes(x=case_cost)+
geom_histogram() +
ggtitle("Histogram of Case Cost") +
labs(x="Case Cost",y="Frequency") +
scale_x_continuous(limits = c(0,300))
# peak is just over 50
# confirm by getting mode
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
getmode(case_cost$case_cost) # 60!
products_1 <- dbGetQuery(con, statement = paste("SELECT category_name, cast(pack as numeric), cast(proof as numeric), cast(case_cost as numeric), cast(bottle_size as numeric)
FROM products"))
products_1 <- products_1 %>% filter(case_cost!='NA') %>% arrange(case_cost)
products_1_gp <- ggplot(products_1)
products_1_gp +
aes(x=proof, y=case_cost)+
geom_point()+
ggtitle("Relationship between proof and case cost") +
labs(x="Proof",y="Case Cost")
products_1_gp +
aes(x=bottle_size, y=case_cost)+
geom_point()+
ggtitle("Relationship between bottle size and case cost") +
labs(x="Bottle Size",y="Case Cost")
min(products_1$bottle_size)
max(products_1$bottle_size)
mean(products_1$bottle_size)
median(products_1$bottle_size)
products_1_gp +
aes(x=bottle_size, y=case_cost)+
geom_point()+
ggtitle("Relationship between bottle size and case cost") +
labs(x="Bottle Size",y="Case Cost") +
scale_x_continuous(limits = c(0,1000))
products_1_gp +
aes(x=pack, y=case_cost)+
geom_point()+
ggtitle("Relationship between pack and case cost") +
labs(x="Pack",y="Case Cost")
ppois(15:20,10)
1-ppois(15:20,10)
qf(.5, df1=12,df2=6)
qf(.05, df1=12,df2=6)
qf(.05, df1=6,df2=12)
qf(.95,df1=12,df2=6)
knitr::opts_chunk$set(echo = TRUE,out.width="0.9\\linewidth",dev="png",fig.align  = 'center')
library(ggplot2)
library(knitr)
library(arm)
library(data.table)
library(foreign)
library(car)
library(stringr)
library(rstan)
library(zoo)
library(dplyr)
library(tidyr)
library(sqldf)
# Read in the data from an excel-format ".csv" file
hiv.data.raw <- fread ("http://www.stat.columbia.edu/~gelman/arm/examples/cd4/allvar.csv")
invisible(hiv.data.raw[,ok := !is.na(CD4PCT) ])
hiv.data<-hiv.data.raw[ok==TRUE]
invisible(hiv.data[,y :=sqrt (CD4PCT)])
# kid's age (yrs) at the beginning of the study
invisible(hiv.data[,age.baseline := baseage ]  )
# kids age (yrs) at the time of measurement
invisible(hiv.data[,age.measurement := visage ] )
invisible(hiv.data[,time := visage - baseage ] )
setnames(hiv.data,"treatmnt","treatment")
fitted_model = hiv.data %>% group_by(newpid) %>% do(model = lm(y ~ time, data = hiv.data))
head(hiv.data)
head(hiv.data.raw)
qf(.95,df1=5,df2=20)
qf(.95,5,20)
1-qf(.05,20,5)
set.seed(3)
grp.1 <- round(rlnorm(100,6)) # with widget
grp.2 <- round(rlnorm(100,6)) # original page
hist(grp.1)
hist(grp.2)
data <- c(grp.1,grp.2)
l1 <- length(grp.1)
l2 <- length(grp.2)
lt <- l1+l2
test.diff <- mean(grp.1) - mean(grp.2)
it <- function(n){
M = NULL
for(i in 1:n){
s = sample(data, lt, FALSE)
m1 = mean(s[1:l1]) - mean(s[(l1+1):lt])
M = c(M,m1)
}
return(M)
}
examples <- it(10000)
par(mfrow=c(1,1))
hist(examples, col = "red", breaks = 100, main="Random Permutations", xlab="")
abline(v = test.diff, col = "black", lwd = 4)
(sum(examples<test.diff))/(10000)
length(examples[examples<test.diff])/10000
set.seed(3)
grp.1 <- round(rlnorm(100, 6)) # With Widget
grp.2 <- round(rlnorm(100, 6)) # Original page
hist(grp.1)
hist(grp.2)
data <- c(grp.1, grp.2)
l1 <- length(grp.1)
l2 <- length(grp.2)
lt <- l1+l2
test.diff <- median(grp.1) - median(grp.2)
it <- function(n){
M = NULL
for(i in 1:n){
s = sample(data, lt, FALSE)
m1 = mean(s[1:l1]) - mean(s[(l1+1):lt])
M = c(M,m1)
}
return(M)
}
set.seed(3)
grp.1 <- round(rlnorm(100, 6)) # With Widget
grp.2 <- round(rlnorm(100, 6)) # Original page
hist(grp.1)
hist(grp.2)
data <- c(grp.1, grp.2)
l1 <- length(grp.1)
l2 <- length(grp.2)
lt <- l1+l2
test.diff <- median(grp.1) - median(grp.2)
it <- function(n){
M = NULL
for(i in 1:n){
s = sample(data, lt, FALSE)
m1 = median(s[1:l1]) - median(s[(l1+1):lt])
M = c(M,m1)
}
return(M)
}
examples <- it(10000)
par(mfrow=c(1,1))
hist(examples, col = "red", breaks = 100, main="Random Permutations", xlab="")
abline(v = test.diff, col = "black", lwd = 4)
set.seed(3)
grp.1 <- round(rlnorm(100, 6)) # With Widget
grp.2 <- round(rlnorm(100, 6)) # Original page
hist(grp.1)
hist(grp.2)
data <- c(grp.1, grp.2)
l1 <- length(grp.1)
l2 <- length(grp.2)
lt <- l1+l2
test.diff <- median(grp.1) - median(grp.2)
it <- function(n){
M = NULL
for(i in 1:n){
s = sample(data, lt, FALSE)
m1 = median(s[1:l1]) - median(s[(l1+1):lt])
M = c(M,m1)
}
return(M)
}
examples <- it(10000)
par(mfrow=c(1,1))
hist(examples, col = "red", breaks = 100, main="Random Permutations", xlab="")
abline(v = test.diff, col = "black", lwd = 4)
abline(v=quantile(examples,0.025), color="white")
abline(v=quantile(examples,0.025), color="yellow")
abline(v=quantile(examples,0.025), col="yellow")
abline(v=quantile(examples,0.025), col="lightblue")
abline(v=quantile(examples,0.025), col="black")
abline(v=quantile(examples,0.025), col="blue")
abline(v=quantile(examples,0.975), col="blue")
library(arm)
0.3/4
invlogit(-0.2+0.3*0.5)
?confint
confint(140, level=0.95)
conf_int_mag <- c(140 - 2*11, 140 + 2*11)
conf_int_mag
conf_int_mag <- c(140 - 2.575*11, 140 + 2.575*11)
conf_int_mag
invlogit(-0.2)
(0.45/0.55)/(0.55/0.45)
exp(-0.2)
exp(-0.1)
exp(0.1)
exp(0.2)
exp(0.3)
(0.45/0.55)
(0.55/0.45)
78 + 76 + 20 + 16
50 + 78 + 11
190 + 139
357 - 329
plot(cars)
devtools::install_github('rweyant/spotifyr')
library(spotifyr)
set_credentials(client_id='a3d8a0232c8742779cfe4ac9f0365d74',client_secret='887cf57aedfa44abb0de94feb94d0a84')
client_tokens <- get_tokens()
get_artist('5me0Irg2ANcsgc93uaYrpb')
biggie <- get_artist('5me0Irg2ANcsgc93uaYrpb')
biggie
biggie <- as.data.frame(biggie)
get_artist('1ZwdS5xdxEREPySFridCfh')
simplify_result(get_artist_relatedartists('5me0Irg2ANcsgc93uaYrpb'),type='artists')
simplify_result(get_artist_relatedartists('1ZwdS5xdxEREPySFridCfh'),type='artists')
get_artist_toptracks('5me0Irg2ANcsgc93uaYrpb','US')
get_artist_toptracks('5me0Irg2ANcsgc93uaYrpb','US')
biggie_top_songs <- as.data.frame(biggie_top_songs)
biggie_top_songs <- get_artist_toptracks('5me0Irg2ANcsgc93uaYrpb','US')
biggie_top_songs <- as.data.frame(biggie_top_songs)
View(biggie_top_songs)
biggie_top_songs <- get_artist_toptracks('5me0Irg2ANcsgc93uaYrpb','US')
biggie_top_songs
library(data.table)
rbindlist(biggie_top_songs, fill=TRUE)
biggie_top_songs
library(dplyr)
dfs <- lapply(biggie_top_songs, data.frame, stringsAsFactors = FALSE)
rbind_all(dfs)
bind_rows(dfs)
View(dfs)
df <- do.call(rbind, lapply(biggie_top_songs, as.data.frame.list, stringsAsFactors = FALSE))
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, comment = FALSE)
library(tidyr)
library(dplyr)
library(readr)
library(ggplot2)
library(leaflet)
setwd("~/Documents/General Assembly/2pacBiggie/Rap-Twitter-Analysis")
us_tweets.df3 <- read_csv('shiny_map/us_tweets.csv')
us_tweets.df3 <- data.frame(us_tweets.df3)
m <- leaflet(us_tweets.df3) %>% addTiles('http://{s}.basemaps.cartocdn.com/dark_all/{z}/{x}/{y}.png',
attribution='Map tiles by <a href="http://stamen.com">Stamen Design</a>, <a href="http://creativecommons.org/licenses/by/3.0">CC BY 3.0</a> &mdash; Map data &copy; <a href="http://www.openstreetmap.org/copyright">OpenStreetMap</a>')
m %>% addCircles(~lon, ~lat, popup=us_tweets.df3$lon, weight = 3, radius=40,
color="#ffa500", stroke = TRUE, fillOpacity = 0.8)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, comment = FALSE)
library(tidyr)
library(dplyr)
library(readr)
library(ggplot2)
library(leaflet)
us_tweets.df3 <- read_csv('shiny_map/us_tweets.csv')
us_tweets.df3 <- data.frame(us_tweets.df3)
m <- leaflet(us_tweets.df3) %>% addTiles('http://{s}.basemaps.cartocdn.com/dark_all/{z}/{x}/{y}.png',
attribution='Map tiles by <a href="http://stamen.com">Stamen Design</a>, <a href="http://creativecommons.org/licenses/by/3.0">CC BY 3.0</a> &mdash; Map data &copy; <a href="http://www.openstreetmap.org/copyright">OpenStreetMap</a>')
# m %>% setView(-100.044345, 41.314352, zoom = 4)
m %>% addCircles(~lon, ~lat, popup=us_tweets.df3$lon, weight = 3, radius=40,
color="#ffa500", stroke = TRUE, fillOpacity = 0.8)
# setView sets central location to NEBRASKA, so we can zoom into the US.
# However, since we have bad data (data outside the United states), this doesn't work.
library(shiny)
shinyAppDir(appDir=
system.file("shiny_twitter_wc", package="shiny"),
options=list(width="100%", height=550))
shinyAppDir(appDir=
system.file("shiny_twitter_wc/shiny_twitter_wc.Rproj", package="shiny"),
options=list(width="100%", height=550))
setwd("~/Documents/General Assembly/2pacBiggie/Rap-Twitter-Analysis/shiny_twitter_wc")
require(tm)
require(SnowballC)
require(wordcloud)
require(streamR)
require(stringr)
require(dplyr)
require(memoise)
library(twitteR)
clean.text <- function(some_txt)
{
some_txt = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", some_txt)
some_txt = gsub("@\\w+", "", some_txt)
some_txt = gsub("[[:punct:]]", "", some_txt)
some_txt = gsub("[[:digit:]]", "", some_txt)
some_txt = gsub("http\\w+", "", some_txt)
some_txt = gsub("[ \t]{2,}", "", some_txt)
some_txt = gsub("^\\s+|\\s+$", "", some_txt)
some_txt = gsub("amp", "", some_txt)
# define "tolower error handling" function
try.tolower = function(x)
{
y = NA
try_error = tryCatch(tolower(x), error=function(e) e)
if (!inherits(try_error, "error"))
y = tolower(x)
return(y)
}
some_txt = sapply(some_txt, try.tolower)
some_txt = some_txt[some_txt != ""]
names(some_txt) = NULL
return(some_txt)
}
tweets.biggie <- parseTweets("biggie.json") # 50 tweets
tweets.biggie <- parseTweets("biggie.json") # 50 tweets
tweets.2pac <- parseTweets("2pac.json") # 216 tweets
library(streamR)
tweets.biggie <- parseTweets("biggie.json") # 50 tweets
tweets.2pac <- parseTweets("2pac.json") # 216 tweets
shiny::runApp()
